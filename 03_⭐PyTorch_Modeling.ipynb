{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkyTCyAzzIbiiDxPVtmPyj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seonae0223/Deep_Learning/blob/main/03_%E2%AD%90PyTorch_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4BuUbGrlyKL",
        "outputId": "d4a43ca0-f5a5-4c7d-d7ec-a75617e1c552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 19778123.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 301677.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5571561.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 14698622.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # 데이터를 저장할 root 디렉토리\n",
        "    train=True, # 훈련용 데이터 설정\n",
        "    download=True, # 다운로드\n",
        "    transform=ToTensor() # 이미지 변환. 여기서는 TorchTesnor로 변환시킵니다.\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_dataloader  = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "JVcCLNsqmCbk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Modeling\n",
        "- 파이토치는 대부분 클래스 기반 모델링을 수행합니다. `torch.nn.Module` 클래스를 상속 받아 만들게 됩니다.\n",
        "- 필수적으로 오버라이딩 해야 하는 메소드는 생성자 `__init__`과 순전파를 담당하는 `forward` 입니다."
      ],
      "metadata": {
        "id": "TRgBFnf_nCq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "# nn.Model : Network 그래프 -> 계산(GPU) 그래프\n",
        "class NeuralNetwork(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    # x는 입력 데이터\n",
        "    # Subclass인 NeuralNetwork의 생성자.\n",
        "    # 여기에서 상위 클래스인 nn.Module의 생성에 대한 책임을 져야 한다. 책임이란? 부모클래스의 생성자에 필요한 파라미터\n",
        "\n",
        "    # super를 이용하여 상위 클래스의 객체 생성 책임을 진다.\n",
        "    # super를 사용했기 때문에 부모 클래스의 객체가 된다.\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "\n",
        "    # 생성자에는 항상 레이어의 구성을 정의\n",
        "    self.flatten = nn.Flatten() # 입력되는 데이터를 평탄화 시키는 레이어\n",
        "\n",
        "    # nn.Sequential을 이용해 연속되는 레이어의 구조를 구성\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "\n",
        "        # 1층 구성\n",
        "        nn.Linear(28*28, 128),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        # 2층(출력층) 구성\n",
        "        nn.Linear(128, 10)\n",
        "    )\n",
        "\n",
        "    # Softmax를 따로 쓰지 않는 이유는 실제 모델 순전파 시에 넣어도 상관 없기 때문!(훈련 할 때)\n",
        "    # 꼭 없어야 하는건 아님. 상황에 따라 넣어 줄 수도 있음\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    #forward에는 입력 데이터 x가 들어온다. 이 때 x의 shape은? (N, 28, 28)\n",
        "    x = self.flatten(x)\n",
        "    y = self.linear_erlu_stack(x)\n",
        "\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "cH28DT7WmDq_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 생성\n",
        "파이토치를 이용해 모델 객체를 만들고 나서 어떤 장치(device) 환경에서 훈련이나 추론을 수행할지 결정지어줘야 합니다."
      ],
      "metadata": {
        "id": "Va0ikm1xyI-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fv5tlS3OyGDr",
        "outputId": "e2ad54eb-bc05-4883-ba77-2d7dabe27818"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 설정한 환경(device)으로 옮긴다는 개념\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7hx3YOrywZD",
        "outputId": "df084085-574e-4df3-df1a-ad31bd3f18d5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OX3UwZBpy24Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
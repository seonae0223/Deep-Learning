{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQ3gHHpD9btOVM3gYOZt/e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seonae0223/Deep_Learning/blob/main/06_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ql0xtnJ_Tz-F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Block 구현"
      ],
      "metadata": {
        "id": "gLxqvNj8Ucll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "\n",
        "  # 나가는 채널을 몇 배 늘려서 나가게 할지 결정\n",
        "  #  사실 18, 34 레이어는 필요 없으나, 구현을 일치성을 위해 놔둠\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, in_channels, inner_channels, stride=1, projection=None):\n",
        "    super().__init__()\n",
        "\n",
        "    # 3x3을 두 번 통과 --> F(x)의 역할\n",
        "    self.residyal = nn.Sequential (\n",
        "        nn.Conv2d(in_channels, inner_channels, 3, stride=stride, bias=False),\n",
        "        nn.BatchNorm2d(inner_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(inner_channels, inner_channels * self.expension, 3, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(inner_channels)\n",
        "    )\n",
        "\n",
        "    # projection은 1x1 conv 진행\n",
        "    self.projention = projection\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # F(x) 부터 계산\n",
        "    residual = self.residual(x)\n",
        "\n",
        "    # skip connection\n",
        "    if self.projection is not None:\n",
        "      # 점선 연결 부분 구현. 이전 스테이지의 마지막 블록의 출력의 채널의 두배로, 세로가로는 절반으로\n",
        "      shortcut = self.projection(x)\n",
        "    else:\n",
        "      shortcut = x\n",
        "\n",
        "    out = self.relu(residual + x)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "zguUWYviUcHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BootleNeck 구현\n",
        "- 50, 101, 152 레이어를 위한 블록"
      ],
      "metadata": {
        "id": "nbhwA0VlZuK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleNeck(nn.Module):\n",
        "\n",
        "  # 내보낼 때 채널이 입력된 데이터의 채널의 4배로 늘어난다. 64 -> 256, 128 -> 512, 512 -> 2048\n",
        "  expansion = 4\n",
        "\n",
        "  def __init__(self, in_channels, inner_channels, stride=1, projection=None):\n",
        "    super().__init__()\n",
        "\n",
        "    # 1x1 -> 3x3 -> 1x1\n",
        "    self.residual = nn.Sequential(\n",
        "        # 1x1\n",
        "        nn.Conv2d(in_channels, inner_channels, 1, bias=False),\n",
        "        nn.BatchNorm2d(inner_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        # 3x3\n",
        "        nn.Conv2d(inner_channels, inner_channels, 3, stride=stride, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(inner_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        # 1x1\n",
        "        nn.Conv2d(inner_channels, inner_channels * self.expansion, 1, bias=False),\n",
        "        nn.BatchNorm2d(inner_channels * self.expansion)\n",
        "    )\n",
        "\n",
        "    self.projection = projection\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    residual = self.residual(x)\n",
        "\n",
        "    if self.projection is not None:\n",
        "      shortcut = self.projection(x)\n",
        "    else:\n",
        "      shortcut = x\n",
        "\n",
        "    out = self.relu(residual + shortcut)\n",
        "    return out"
      ],
      "metadata": {
        "id": "ftAOUVIIUkgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet 모듈 구현\n"
      ],
      "metadata": {
        "id": "xAXk4Md8dCHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "  def __init__(self, block, num_block_list, num_classes=1000, zero_init_residual=True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels = 64\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.stage1 = self.make_stage(block, 64, num_block_list[0], stride=1)\n",
        "    self.stage2 = self.make_stage(block, 128, num_block_list[1], stride=2)\n",
        "    self.stage3 = self.make_stage(block, 256, num_block_list[2], stride=2)\n",
        "    self.stage4 = self.make_stage(block, 512, num_block_list[3], stride=2)\n",
        "\n",
        "    if zero_init_residual:\n",
        "      # 전체 모듈 가져오기\n",
        "      for m in self.modules():\n",
        "\n",
        "        # 모듈이 block이라면(BottleNeck이거나 BasicBlock 이라면)\n",
        "        if isinstance(m, block):\n",
        "          # residual 모듈의 제일 마지막 레이어의 가중치를 0으로 만들어 준다.\n",
        "          #  residual 모듈의 제일 마지막 레이어는 Batch Normalization\n",
        "            # 각 모듈의 마지막 층은 BatchNorm2d입니다. 이 BatchNorm2d의 weight 파라미터(γ 또는 alpha라고도 부릅니다)를 0으로 초기화합니다.\n",
        "            # γ를 0으로 설정하면 해당 BatchNorm 층의 출력이 0이 되어 residual branch의 전체 출력이 0이 됩니다.\n",
        "            # 따라서 이 residual branch는 초기에는 출력을 하지 않고, 블록 전체는 입력을 그대로 출력하는 identity mapping처럼 동작합니다.\n",
        "            # 이는 초기 학습 시 네트워크의 안정적인 수렴을 도와주며, 모델의 성능을 향상시킵니다.\n",
        "            # 이러한 방법은 논문 https://arxiv.org/abs/1706.02677 에서 제안되었으며, 약 0.2~0.3%의 성능 향상이 있다고 합니다.\n",
        "          nn.init.constant_(m.residual[-1].weight, 0) # BN의 가중치를 0으로 만들어 준다.\n",
        "\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # 입력된 이미지에 대한 기본 처리\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    # 잔차 학습(스테이지 통과)\n",
        "    x = self.stage1(x)\n",
        "    x = self.stage2(x)\n",
        "    x = self.stage3(x)\n",
        "    x = self.stage4(x)\n",
        "\n",
        "    # FCL\n",
        "    x = self.avgpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    y = self.fc(x)\n",
        "\n",
        "    return y\n",
        "\n",
        "  def make_stage(self, block, inner_channels, num_blocks, stride=1):\n",
        "\n",
        "    if stride != 1 or self.in_channels != inner_channels * block.expansion:\n",
        "      projection = nn.Sequential(\n",
        "          nn.Conv2d(self.in_channels, inner_channels * block.expansion, 1, stride=stride, bias=False),\n",
        "          nn.BatchNorm2d(inner_channels * block.expansion)\n",
        "      )\n",
        "    else:\n",
        "      projection = None\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    # 각 스테이지 별 첫 번째 레이어는 projection을 수행한다. 아닌 경우에는 그냥 None으로 들어간다.\n",
        "    layers += [ block(self.in_channels, inner_channels, stride, projection) ]\n",
        "\n",
        "    self.in_channels = inner_channels * block.expansion\n",
        "\n",
        "    for _ in range(1, num_blocks):\n",
        "      layers += [block(self.in_channels, inner_channels)] # 첫 번째 레이어 이후는 stride, projection 없음\n",
        "\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "WgLDuNZqc2jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet18(**kwargs):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "\n",
        "def resnet34(**kwargs):\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "\n",
        "########\n",
        "\n",
        "def resnet50(**kwargs):\n",
        "    return ResNet(BottleNeck, [3, 4, 6, 3], **kwargs)\n",
        "\n",
        "def resnet101(**kwargs):\n",
        "    return ResNet(BottleNeck, [3, 4, 23, 3], **kwargs)\n",
        "\n",
        "def resnet152(**kwargs):\n",
        "    return ResNet(BottleNeck, [3, 8, 36, 3], **kwargs)"
      ],
      "metadata": {
        "id": "1MKl4eR4tuAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet101()"
      ],
      "metadata": {
        "id": "ORoJuWRBxm9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kzYdyRxoL-",
        "outputId": "b1659d36-90a9-4ae9-aee4-4a6811a416f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(model, input_size=(64, 3, 224, 224), device='cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVCBFCFlx7iY",
        "outputId": "2fa6f71a-9cc4-4c70-ca4e-d17cb85dac2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNet                                   [64, 1000]                --\n",
              "├─Conv2d: 1-1                            [64, 64, 112, 112]        9,408\n",
              "├─BatchNorm2d: 1-2                       [64, 64, 112, 112]        128\n",
              "├─ReLU: 1-3                              [64, 64, 112, 112]        --\n",
              "├─MaxPool2d: 1-4                         [64, 64, 56, 56]          --\n",
              "├─Sequential: 1-5                        [64, 256, 56, 56]         --\n",
              "│    └─BottleNeck: 2-1                   [64, 256, 56, 56]         --\n",
              "│    │    └─Sequential: 3-1              [64, 256, 56, 56]         58,112\n",
              "│    │    └─Sequential: 3-2              [64, 256, 56, 56]         16,896\n",
              "│    │    └─ReLU: 3-3                    [64, 256, 56, 56]         --\n",
              "│    └─BottleNeck: 2-2                   [64, 256, 56, 56]         --\n",
              "│    │    └─Sequential: 3-4              [64, 256, 56, 56]         70,400\n",
              "│    │    └─ReLU: 3-5                    [64, 256, 56, 56]         --\n",
              "│    └─BottleNeck: 2-3                   [64, 256, 56, 56]         --\n",
              "│    │    └─Sequential: 3-6              [64, 256, 56, 56]         70,400\n",
              "│    │    └─ReLU: 3-7                    [64, 256, 56, 56]         --\n",
              "├─Sequential: 1-6                        [64, 512, 28, 28]         --\n",
              "│    └─BottleNeck: 2-4                   [64, 512, 28, 28]         --\n",
              "│    │    └─Sequential: 3-8              [64, 512, 28, 28]         247,296\n",
              "│    │    └─Sequential: 3-9              [64, 512, 28, 28]         132,096\n",
              "│    │    └─ReLU: 3-10                   [64, 512, 28, 28]         --\n",
              "│    └─BottleNeck: 2-5                   [64, 512, 28, 28]         --\n",
              "│    │    └─Sequential: 3-11             [64, 512, 28, 28]         280,064\n",
              "│    │    └─ReLU: 3-12                   [64, 512, 28, 28]         --\n",
              "│    └─BottleNeck: 2-6                   [64, 512, 28, 28]         --\n",
              "│    │    └─Sequential: 3-13             [64, 512, 28, 28]         280,064\n",
              "│    │    └─ReLU: 3-14                   [64, 512, 28, 28]         --\n",
              "│    └─BottleNeck: 2-7                   [64, 512, 28, 28]         --\n",
              "│    │    └─Sequential: 3-15             [64, 512, 28, 28]         280,064\n",
              "│    │    └─ReLU: 3-16                   [64, 512, 28, 28]         --\n",
              "├─Sequential: 1-7                        [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-8                   [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-17             [64, 1024, 14, 14]        986,112\n",
              "│    │    └─Sequential: 3-18             [64, 1024, 14, 14]        526,336\n",
              "│    │    └─ReLU: 3-19                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-9                   [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-20             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-21                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-10                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-22             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-23                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-11                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-24             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-25                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-12                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-26             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-27                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-13                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-28             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-29                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-14                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-30             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-31                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-15                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-32             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-33                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-16                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-34             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-35                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-17                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-36             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-37                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-18                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-38             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-39                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-19                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-40             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-41                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-20                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-42             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-43                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-21                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-44             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-45                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-22                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-46             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-47                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-23                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-48             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-49                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-24                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-50             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-51                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-25                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-52             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-53                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-26                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-54             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-55                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-27                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-56             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-57                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-28                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-58             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-59                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-29                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-60             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-61                   [64, 1024, 14, 14]        --\n",
              "│    └─BottleNeck: 2-30                  [64, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-62             [64, 1024, 14, 14]        1,117,184\n",
              "│    │    └─ReLU: 3-63                   [64, 1024, 14, 14]        --\n",
              "├─Sequential: 1-8                        [64, 2048, 7, 7]          --\n",
              "│    └─BottleNeck: 2-31                  [64, 2048, 7, 7]          --\n",
              "│    │    └─Sequential: 3-64             [64, 2048, 7, 7]          3,938,304\n",
              "│    │    └─Sequential: 3-65             [64, 2048, 7, 7]          2,101,248\n",
              "│    │    └─ReLU: 3-66                   [64, 2048, 7, 7]          --\n",
              "│    └─BottleNeck: 2-32                  [64, 2048, 7, 7]          --\n",
              "│    │    └─Sequential: 3-67             [64, 2048, 7, 7]          4,462,592\n",
              "│    │    └─ReLU: 3-68                   [64, 2048, 7, 7]          --\n",
              "│    └─BottleNeck: 2-33                  [64, 2048, 7, 7]          --\n",
              "│    │    └─Sequential: 3-69             [64, 2048, 7, 7]          4,462,592\n",
              "│    │    └─ReLU: 3-70                   [64, 2048, 7, 7]          --\n",
              "├─AdaptiveAvgPool2d: 1-9                 [64, 2048, 1, 1]          --\n",
              "├─Linear: 1-10                           [64, 1000]                2,049,000\n",
              "==========================================================================================\n",
              "Total params: 44,549,160\n",
              "Trainable params: 44,549,160\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 499.30\n",
              "==========================================================================================\n",
              "Input size (MB): 38.54\n",
              "Forward/backward pass size (MB): 16622.01\n",
              "Params size (MB): 178.20\n",
              "Estimated Total Size (MB): 16838.75\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BfokZflMx9Aw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}